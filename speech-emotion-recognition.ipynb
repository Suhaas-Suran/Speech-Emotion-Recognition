{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n## Importing Modules\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-28T13:21:29.124541Z","iopub.execute_input":"2023-09-28T13:21:29.124913Z","iopub.status.idle":"2023-09-28T13:21:29.130150Z","shell.execute_reply.started":"2023-09-28T13:21:29.124885Z","shell.execute_reply":"2023-09-28T13:21:29.129136Z"}}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport librosa\nimport librosa.display\nfrom IPython.display import Audio\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:41:10.354425Z","iopub.execute_input":"2023-09-28T13:41:10.355464Z","iopub.status.idle":"2023-09-28T13:41:10.363107Z","shell.execute_reply.started":"2023-09-28T13:41:10.355434Z","shell.execute_reply":"2023-09-28T13:41:10.362224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the Dataset","metadata":{}},{"cell_type":"code","source":"# Initialize lists to store file paths and labels\npaths = []\nlabels = []\n\n# Walk through the directory structure and collect file paths and labels\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        paths.append(os.path.join(dirname, filename))\n        # Extract and preprocess labels from filenames\n        label = filename.split('_')[-1]\n        label = label.split('.')[0]\n        labels.append(label.lower())\n    # Limit the number of files to 2800 for loading efficiency\n    if len(paths) == 2800:\n        break\n\n# Print a message indicating that the dataset is loaded\nprint('Dataset is Loaded')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:38:31.488565Z","iopub.execute_input":"2023-09-28T13:38:31.489276Z","iopub.status.idle":"2023-09-28T13:38:32.364631Z","shell.execute_reply.started":"2023-09-28T13:38:31.489246Z","shell.execute_reply":"2023-09-28T13:38:32.363642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the first few file paths and labels\npaths[:5]","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:38:32.366245Z","iopub.execute_input":"2023-09-28T13:38:32.366604Z","iopub.status.idle":"2023-09-28T13:38:32.375919Z","shell.execute_reply.started":"2023-09-28T13:38:32.366570Z","shell.execute_reply":"2023-09-28T13:38:32.374791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels[:5]","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:38:32.380501Z","iopub.execute_input":"2023-09-28T13:38:32.380913Z","iopub.status.idle":"2023-09-28T13:38:32.392765Z","shell.execute_reply.started":"2023-09-28T13:38:32.380790Z","shell.execute_reply":"2023-09-28T13:38:32.391752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a DataFrame to store file paths and labels\ndf = pd.DataFrame()\ndf['speech'] = paths\ndf['label'] = labels\n\n# Display the first few rows of the DataFrame\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:38:32.394223Z","iopub.execute_input":"2023-09-28T13:38:32.395853Z","iopub.status.idle":"2023-09-28T13:38:32.504175Z","shell.execute_reply.started":"2023-09-28T13:38:32.395805Z","shell.execute_reply":"2023-09-28T13:38:32.503279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"# Count and visualize the distribution of labels\ndf['label'].value_counts()\nsns.countplot(data=df, x='label')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:38:32.508122Z","iopub.execute_input":"2023-09-28T13:38:32.510552Z","iopub.status.idle":"2023-09-28T13:38:32.939294Z","shell.execute_reply.started":"2023-09-28T13:38:32.510517Z","shell.execute_reply":"2023-09-28T13:38:32.938248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to plot the waveform of audio data\ndef waveplot(data, sr, emotion):\n    plt.figure(figsize=(10, 4))\n    plt.title(emotion, size=20)\n    librosa.display.waveshow(data, sr=sr)\n    plt.show()\n\n# Define a function to plot the spectrogram of audio data\ndef spectrogram(data, sr, emotion):\n    x = librosa.stft(data)\n    xdb = librosa.amplitude_to_db(abs(x))\n    plt.figure(figsize=(11, 4))\n    plt.title(emotion, size=20)\n    librosa.display.specshow(xdb, sr=sr, x_axis='time', y_axis='hz')\n    plt.colorbar()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:38:32.943376Z","iopub.execute_input":"2023-09-28T13:38:32.945710Z","iopub.status.idle":"2023-09-28T13:38:32.955536Z","shell.execute_reply.started":"2023-09-28T13:38:32.945677Z","shell.execute_reply":"2023-09-28T13:38:32.953850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'fear'\npath = np.array(df['speech'][df['label'] == emotion])[0]\ndata, sampling_rate = librosa.load(path)\n\nwaveplot(data, sampling_rate, emotion)\nspectrogram(data, sampling_rate, emotion)\nAudio(path)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:38:32.957115Z","iopub.execute_input":"2023-09-28T13:38:32.957544Z","iopub.status.idle":"2023-09-28T13:38:43.258532Z","shell.execute_reply.started":"2023-09-28T13:38:32.957511Z","shell.execute_reply":"2023-09-28T13:38:43.257426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'angry'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectrogram(data, sampling_rate, emotion)\nAudio(path)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:38:43.260388Z","iopub.execute_input":"2023-09-28T13:38:43.260962Z","iopub.status.idle":"2023-09-28T13:38:44.260180Z","shell.execute_reply.started":"2023-09-28T13:38:43.260925Z","shell.execute_reply":"2023-09-28T13:38:44.259156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'disgust'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectrogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:38:44.265008Z","iopub.execute_input":"2023-09-28T13:38:44.265773Z","iopub.status.idle":"2023-09-28T13:38:45.358526Z","shell.execute_reply.started":"2023-09-28T13:38:44.265744Z","shell.execute_reply":"2023-09-28T13:38:45.357527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'neutral'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectrogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:38:45.359971Z","iopub.execute_input":"2023-09-28T13:38:45.360903Z","iopub.status.idle":"2023-09-28T13:38:46.527585Z","shell.execute_reply.started":"2023-09-28T13:38:45.360867Z","shell.execute_reply":"2023-09-28T13:38:46.526678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'sad'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectrogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:38:46.529063Z","iopub.execute_input":"2023-09-28T13:38:46.529681Z","iopub.status.idle":"2023-09-28T13:38:47.633372Z","shell.execute_reply.started":"2023-09-28T13:38:46.529646Z","shell.execute_reply":"2023-09-28T13:38:47.632500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'ps'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectrogram(data, sampling_rate, emotion)\nAudio(path)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:38:47.634936Z","iopub.execute_input":"2023-09-28T13:38:47.635558Z","iopub.status.idle":"2023-09-28T13:38:48.705452Z","shell.execute_reply.started":"2023-09-28T13:38:47.635524Z","shell.execute_reply":"2023-09-28T13:38:48.704540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'happy'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectrogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:38:48.707063Z","iopub.execute_input":"2023-09-28T13:38:48.707708Z","iopub.status.idle":"2023-09-28T13:38:49.791495Z","shell.execute_reply.started":"2023-09-28T13:38:48.707673Z","shell.execute_reply":"2023-09-28T13:38:49.790545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extraction","metadata":{}},{"cell_type":"code","source":"# Define a function to extract MFCC features from an audio file\ndef extract_mfcc(filename):\n    y, sr = librosa.load(filename, duration=3, offset=0.5)\n    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n    return mfcc","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:38:49.792961Z","iopub.execute_input":"2023-09-28T13:38:49.793996Z","iopub.status.idle":"2023-09-28T13:38:49.800224Z","shell.execute_reply.started":"2023-09-28T13:38:49.793955Z","shell.execute_reply":"2023-09-28T13:38:49.799090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example: Extracting MFCC features for the first file\nextract_mfcc(df['speech'][0])","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:38:49.801671Z","iopub.execute_input":"2023-09-28T13:38:49.802731Z","iopub.status.idle":"2023-09-28T13:38:50.842444Z","shell.execute_reply.started":"2023-09-28T13:38:49.802693Z","shell.execute_reply":"2023-09-28T13:38:50.841405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply MFCC extraction to all audio files in the DataFrame\nX_mfcc = df['speech'].apply(lambda x: extract_mfcc(x))\nX_mfcc","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:38:50.843910Z","iopub.execute_input":"2023-09-28T13:38:50.844861Z","iopub.status.idle":"2023-09-28T13:40:10.279712Z","shell.execute_reply.started":"2023-09-28T13:38:50.844827Z","shell.execute_reply":"2023-09-28T13:40:10.278271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the MFCC data to a numpy array\nX = [x for x in X_mfcc]\nX = np.array(X)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:40:10.281274Z","iopub.execute_input":"2023-09-28T13:40:10.281721Z","iopub.status.idle":"2023-09-28T13:40:10.292122Z","shell.execute_reply.started":"2023-09-28T13:40:10.281606Z","shell.execute_reply":"2023-09-28T13:40:10.290898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the shape of the MFCC data\nX.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:40:10.293749Z","iopub.execute_input":"2023-09-28T13:40:10.294211Z","iopub.status.idle":"2023-09-28T13:40:10.305773Z","shell.execute_reply.started":"2023-09-28T13:40:10.294172Z","shell.execute_reply":"2023-09-28T13:40:10.304535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reshape the data to add a channel dimension\nX = np.expand_dims(X, -1)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:40:10.307205Z","iopub.execute_input":"2023-09-28T13:40:10.307835Z","iopub.status.idle":"2023-09-28T13:40:10.319312Z","shell.execute_reply.started":"2023-09-28T13:40:10.307804Z","shell.execute_reply":"2023-09-28T13:40:10.317975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform one-hot encoding for labels\nfrom sklearn.preprocessing import OneHotEncoder\nenc = OneHotEncoder()\ny = enc.fit_transform(df[['label']])\ny = y.toarray()\ny.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:40:10.320925Z","iopub.execute_input":"2023-09-28T13:40:10.321382Z","iopub.status.idle":"2023-09-28T13:40:10.405265Z","shell.execute_reply.started":"2023-09-28T13:40:10.321322Z","shell.execute_reply":"2023-09-28T13:40:10.404316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating the LSTM Model","metadata":{}},{"cell_type":"code","source":"# Import Keras libraries for building the neural network model\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:40:10.406912Z","iopub.execute_input":"2023-09-28T13:40:10.407672Z","iopub.status.idle":"2023-09-28T13:40:18.765347Z","shell.execute_reply.started":"2023-09-28T13:40:10.407619Z","shell.execute_reply":"2023-09-28T13:40:18.764318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the neural network model\nmodel = Sequential([\n    LSTM(256, return_sequences=False, input_shape=(40, 1)),\n    Dropout(0.2),\n    Dense(128, activation='relu'),\n    Dropout(0.2),\n    Dense(64, activation='relu'),\n    Dropout(0.2),\n    Dense(7, activation='softmax')\n])\n\n# Compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Display model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:40:18.766918Z","iopub.execute_input":"2023-09-28T13:40:18.767678Z","iopub.status.idle":"2023-09-28T13:40:23.867598Z","shell.execute_reply.started":"2023-09-28T13:40:18.767639Z","shell.execute_reply":"2023-09-28T13:40:23.866839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(X, y, validation_split=0.2, epochs=50, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:40:23.868682Z","iopub.execute_input":"2023-09-28T13:40:23.869033Z","iopub.status.idle":"2023-09-28T13:41:06.860968Z","shell.execute_reply.started":"2023-09-28T13:40:23.869000Z","shell.execute_reply":"2023-09-28T13:41:06.859874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot the results","metadata":{}},{"cell_type":"code","source":"# Plot training history - accuracy\nepochs = list(range(50))\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nplt.plot(epochs, acc, label='train accuracy')\nplt.plot(epochs, val_acc, label='val accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:41:06.863164Z","iopub.execute_input":"2023-09-28T13:41:06.863870Z","iopub.status.idle":"2023-09-28T13:41:07.597489Z","shell.execute_reply.started":"2023-09-28T13:41:06.863835Z","shell.execute_reply":"2023-09-28T13:41:07.595674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training history - loss\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.plot(epochs, loss, label='train loss')\nplt.plot(epochs, val_loss, label='val loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:41:07.598700Z","iopub.execute_input":"2023-09-28T13:41:07.599081Z","iopub.status.idle":"2023-09-28T13:41:07.955807Z","shell.execute_reply.started":"2023-09-28T13:41:07.599047Z","shell.execute_reply":"2023-09-28T13:41:07.954666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building a Predictive System","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:41:07.957607Z","iopub.execute_input":"2023-09-28T13:41:07.958000Z","iopub.status.idle":"2023-09-28T13:41:08.420043Z","shell.execute_reply.started":"2023-09-28T13:41:07.957965Z","shell.execute_reply":"2023-09-28T13:41:08.418992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reshape the data to remove the channel dimension\nX = np.squeeze(X, axis=-1)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:41:08.426342Z","iopub.execute_input":"2023-09-28T13:41:08.426727Z","iopub.status.idle":"2023-09-28T13:41:08.432286Z","shell.execute_reply.started":"2023-09-28T13:41:08.426695Z","shell.execute_reply":"2023-09-28T13:41:08.431109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:41:08.433789Z","iopub.execute_input":"2023-09-28T13:41:08.434204Z","iopub.status.idle":"2023-09-28T13:41:08.446183Z","shell.execute_reply.started":"2023-09-28T13:41:08.434169Z","shell.execute_reply":"2023-09-28T13:41:08.445270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize and train the RandomForestClassifier\nrf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_classifier.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:41:08.448883Z","iopub.execute_input":"2023-09-28T13:41:08.449835Z","iopub.status.idle":"2023-09-28T13:41:10.236979Z","shell.execute_reply.started":"2023-09-28T13:41:08.449802Z","shell.execute_reply":"2023-09-28T13:41:10.235833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test set\ny_pred = rf_classifier.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:41:10.238861Z","iopub.execute_input":"2023-09-28T13:41:10.239245Z","iopub.status.idle":"2023-09-28T13:41:10.306243Z","shell.execute_reply.started":"2023-09-28T13:41:10.239210Z","shell.execute_reply":"2023-09-28T13:41:10.305312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model's performance\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:41:10.307422Z","iopub.execute_input":"2023-09-28T13:41:10.307768Z","iopub.status.idle":"2023-09-28T13:41:10.321271Z","shell.execute_reply.started":"2023-09-28T13:41:10.307735Z","shell.execute_reply":"2023-09-28T13:41:10.319122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate a classification report\nclass_report = classification_report(y_test, y_pred)\nprint(\"Classification Report:\\n\", class_report)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:41:10.322712Z","iopub.execute_input":"2023-09-28T13:41:10.323267Z","iopub.status.idle":"2023-09-28T13:41:10.344604Z","shell.execute_reply.started":"2023-09-28T13:41:10.323221Z","shell.execute_reply":"2023-09-28T13:41:10.343608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to predict emotion from a new audio file\ndef predict_emotion(audio_file_path):\n    y, sr = librosa.load(audio_file_path, duration=3, offset=0.5)\n    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n    predicted_emotion = rf_classifier.predict([mfcc])  # Pass a 2D array with one sample\n    return predicted_emotion[0]\n\n# Example usage:\n# Replace 'your_audio_file.wav' with the path to your audio file\n# predicted_emotion = predict_emotion('your_audio_file.wav')\n# print(f\"Predicted Emotion: {predicted_emotion}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:41:10.346101Z","iopub.execute_input":"2023-09-28T13:41:10.346435Z","iopub.status.idle":"2023-09-28T13:41:10.353213Z","shell.execute_reply.started":"2023-09-28T13:41:10.346404Z","shell.execute_reply":"2023-09-28T13:41:10.352215Z"},"trusted":true},"execution_count":null,"outputs":[]}]}